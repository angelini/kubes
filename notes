# Read Kafka topic
kafka/bin/kafka-console-consumer.sh --bootstrap-server ${KAFKA_SERVICE_HOST}:${KAFKA_SERVICE_PORT} --topic sample_topic --from-beginning

# Start spark-shell with Kafka package
spark/bin/spark-shell \
  --master spark://${SPARK_MASTER_SERVICE_HOST}:${SPARK_MASTER_SERVICE_PORT} \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.1.0

# Start pyspark shell from Jupyter
import os
import pyspark
master_uri = 'spark://{}:{}'.format(os.environ.get('SPARK_MASTER_SERVICE_HOST'),
                                    os.environ.get('SPARK_MASTER_SERVICE_PORT'))
print(master_uri)
spark = pyspark.sql.SparkSession.builder \
    .master(master_uri) \
    .getOrCreate()

# Connect to a Kafka topic via Structured Streaming
val ds = spark.readStream.format("kafka").option("kafka.bootstrap.servers", s"${sys.env("KAFKA_SERVICE_HOST")}:${sys.env("KAFKA_SERVICE_PORT")}").option("subscribe", "sample_topic").load()
val df = ds.selectExpr("CAST(key AS STRING)", "CAST(value AS STRING)").as[(String, String)]
val query = df.writeStream.format("console").start()
